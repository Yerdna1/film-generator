// Unified TTS API Route - Routes to appropriate provider based on user settings
// Supports: Gemini TTS, ElevenLabs, Modal (self-hosted), OpenAI TTS

import { NextRequest, NextResponse } from 'next/server';
import { prisma } from '@/lib/db/prisma';
import { optionalAuth, requireCredits, uploadMediaToS3 } from '@/lib/api';
import { spendCredits, COSTS } from '@/lib/services/credits';
import { calculateVoiceCost } from '@/lib/services/real-costs';
import { rateLimit } from '@/lib/services/rate-limit';
import type { TTSProvider } from '@/types/project';

const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta';
const ELEVENLABS_API_URL = 'https://api.elevenlabs.io/v1';
const OPENAI_API_URL = 'https://api.openai.com/v1/audio/speech';

export const maxDuration = 60;

interface TTSRequest {
  text: string;
  voiceId?: string;
  voiceName?: string;
  language?: string;
  projectId?: string;
  provider?: TTSProvider;  // Allow overriding provider from UI
  skipCreditCheck?: boolean; // Skip credit check when user provides own API key
  model?: string; // Model ID from project model config (for KIE TTS)
  // Voice customization settings
  voiceInstructions?: string;      // OpenAI: speaking style instructions
  voiceStability?: number;         // ElevenLabs: 0-1
  voiceSimilarityBoost?: number;   // ElevenLabs: 0-1
  voiceStyle?: number;             // ElevenLabs: 0-1
}

// Add WAV headers to raw PCM audio data
function addWavHeaders(pcmData: Buffer, sampleRate: number, numChannels: number, bitsPerSample: number): Buffer {
  const byteRate = sampleRate * numChannels * (bitsPerSample / 8);
  const blockAlign = numChannels * (bitsPerSample / 8);
  const dataSize = pcmData.length;
  const headerSize = 44;
  const fileSize = headerSize + dataSize - 8;

  const header = Buffer.alloc(headerSize);
  header.write('RIFF', 0);
  header.writeUInt32LE(fileSize, 4);
  header.write('WAVE', 8);
  header.write('fmt ', 12);
  header.writeUInt32LE(16, 16);
  header.writeUInt16LE(1, 20);
  header.writeUInt16LE(numChannels, 22);
  header.writeUInt32LE(sampleRate, 24);
  header.writeUInt32LE(byteRate, 28);
  header.writeUInt16LE(blockAlign, 32);
  header.writeUInt16LE(bitsPerSample, 34);
  header.write('data', 36);
  header.writeUInt32LE(dataSize, 40);

  return Buffer.concat([header, pcmData]);
}

// Generate audio using Gemini TTS
async function generateWithGemini(
  text: string,
  voiceName: string,
  language: string,
  projectId: string | undefined,
  apiKey: string,
  userId: string | undefined
): Promise<{ audioUrl: string; cost: number; storage: string }> {
  const formattedText = language === 'sk'
    ? `Hovor po slovensky s prirodzeným prízvukom: "${text}"`
    : text;

  const response = await fetch(
    `${GEMINI_API_URL}/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents: [{ parts: [{ text: formattedText }] }],
        generationConfig: {
          responseModalities: ['AUDIO'],
          speechConfig: {
            voiceConfig: { prebuiltVoiceConfig: { voiceName } },
          },
        },
      }),
    }
  );

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.error?.message || 'Failed to generate speech with Gemini');
  }

  const data = await response.json();
  const audioData = data.candidates?.[0]?.content?.parts?.[0]?.inlineData;

  if (!audioData) {
    throw new Error('No audio generated by Gemini');
  }

  let base64AudioUrl: string;
  const mimeType = audioData.mimeType?.toLowerCase() || '';

  if (mimeType.includes('l16') || mimeType.includes('pcm')) {
    const rateMatch = mimeType.match(/rate=(\d+)/);
    const sampleRate = rateMatch ? parseInt(rateMatch[1]) : 24000;
    const pcmBuffer = Buffer.from(audioData.data, 'base64');
    const wavBuffer = addWavHeaders(pcmBuffer, sampleRate, 1, 16);
    base64AudioUrl = `data:audio/wav;base64,${wavBuffer.toString('base64')}`;
  } else {
    base64AudioUrl = `data:${audioData.mimeType};base64,${audioData.data}`;
  }

  const realCost = calculateVoiceCost(text.length, 'geminiTts');

  if (userId) {
    await spendCredits(userId, COSTS.VOICEOVER_LINE, 'voiceover', `Gemini TTS (${text.length} chars)`, projectId, 'gemini-tts', { characterCount: text.length }, realCost);
  }

  const audioUrl = await uploadMediaToS3(base64AudioUrl, 'audio', projectId);

  return { audioUrl, cost: realCost, storage: !audioUrl.startsWith('data:') ? 's3' : 'base64' };
}

// Generate audio using ElevenLabs
async function generateWithElevenLabs(
  text: string,
  voiceId: string,
  projectId: string | undefined,
  apiKey: string,
  userId: string | undefined,
  stability: number,
  similarityBoost: number,
  style: number
): Promise<{ audioUrl: string; cost: number; storage: string }> {
  const response = await fetch(
    `${ELEVENLABS_API_URL}/text-to-speech/${voiceId}`,
    {
      method: 'POST',
      headers: {
        'xi-api-key': apiKey,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        text,
        model_id: 'eleven_multilingual_v2',
        voice_settings: {
          stability,
          similarity_boost: similarityBoost,
          style,
          use_speaker_boost: true,
        },
      }),
    }
  );

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.detail?.message || 'Failed to generate speech with ElevenLabs');
  }

  const audioBlob = await response.blob();
  const audioBuffer = await audioBlob.arrayBuffer();
  const base64 = Buffer.from(audioBuffer).toString('base64');
  const base64AudioUrl = `data:audio/mpeg;base64,${base64}`;

  const realCost = calculateVoiceCost(text.length, 'elevenlabs');

  if (userId) {
    await spendCredits(userId, COSTS.VOICEOVER_LINE, 'voiceover', `ElevenLabs TTS (${text.length} chars)`, projectId, 'elevenlabs', { characterCount: text.length }, realCost);
  }

  const audioUrl = await uploadMediaToS3(base64AudioUrl, 'audio', projectId);

  return { audioUrl, cost: realCost, storage: !audioUrl.startsWith('data:') ? 's3' : 'base64' };
}

// Generate audio using OpenAI TTS (gpt-4o-mini-tts)
async function generateWithOpenAI(
  text: string,
  voiceId: string,
  language: string,
  projectId: string | undefined,
  apiKey: string,
  userId: string | undefined,
  voiceInstructions?: string
): Promise<{ audioUrl: string; cost: number; storage: string }> {
  console.log('[OpenAI TTS] Generating with voice:', voiceId);

  // Combine language instructions with user-provided voice instructions
  const languageInstruction = language === 'sk'
    ? 'Speak in Slovak with natural pronunciation and intonation.'
    : '';

  // Merge language and custom instructions
  const instructions = [languageInstruction, voiceInstructions].filter(Boolean).join(' ') || undefined;

  const response = await fetch(OPENAI_API_URL, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'gpt-4o-mini-tts',
      input: text,
      voice: voiceId,
      response_format: 'mp3',
      ...(instructions && { instructions }),
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`OpenAI TTS generation failed: ${errorText}`);
  }

  // Get audio as blob
  const audioBlob = await response.blob();
  const audioBuffer = await audioBlob.arrayBuffer();
  const base64 = Buffer.from(audioBuffer).toString('base64');
  const base64AudioUrl = `data:audio/mpeg;base64,${base64}`;

  // OpenAI TTS pricing: $15 per 1M characters = $0.015 per 1K chars
  const realCost = calculateVoiceCost(text.length, 'openaiTts');

  if (userId) {
    await spendCredits(userId, COSTS.VOICEOVER_LINE, 'voiceover', `OpenAI TTS (${text.length} chars)`, projectId, 'openai-tts', { characterCount: text.length }, realCost);
  }

  const audioUrl = await uploadMediaToS3(base64AudioUrl, 'audio', projectId);

  return { audioUrl, cost: realCost, storage: !audioUrl.startsWith('data:') ? 's3' : 'base64' };
}

// Generate audio using Modal (self-hosted)
async function generateWithModal(
  text: string,
  voiceId: string | undefined,
  language: string,
  projectId: string | undefined,
  modalEndpoint: string,
  userId: string | undefined
): Promise<{ audioUrl: string; cost: number; storage: string }> {
  console.log('[Modal] Generating TTS with endpoint:', modalEndpoint);

  const response = await fetch(modalEndpoint, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      text,
      voice_id: voiceId,
      language,
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Modal TTS generation failed: ${errorText}`);
  }

  const data = await response.json();

  let audioUrl: string;
  if (data.audio) {
    audioUrl = data.audio.startsWith('data:') ? data.audio : `data:audio/wav;base64,${data.audio}`;
  } else if (data.audioUrl) {
    audioUrl = data.audioUrl;
  } else {
    throw new Error('Modal endpoint did not return audio');
  }

  const realCost = 0.01; // Modal GPU cost per TTS line (~$0.01)

  if (userId) {
    await spendCredits(userId, COSTS.VOICEOVER_LINE, 'voiceover', `Modal TTS (${text.length} chars)`, projectId, 'modal', { characterCount: text.length }, realCost);
  }

  audioUrl = await uploadMediaToS3(audioUrl, 'audio', projectId);

  return { audioUrl, cost: realCost, storage: audioUrl.startsWith('data:') ? 'base64' : 's3' };
}

// Generate audio using KIE AI (ElevenLabs via KIE)
async function generateWithKie(
  text: string,
  voiceId: string,
  projectId: string | undefined,
  modelId: string,
  apiKey: string,
  userId: string | undefined,
  voiceSettings?: {
    stability?: number;
    similarityBoost?: number;
    style?: number;
  }
): Promise<{ audioUrl: string; cost: number; storage: string }> {
  console.log(`[KIE TTS] Generating with model: ${modelId}`);

  // Query model from database instead of constants file
  const modelConfig = await prisma.kieTtsModel.findUnique({
    where: { modelId }
  });

  if (!modelConfig || !modelConfig.isActive) {
    throw new Error(`Invalid KIE TTS model: ${modelId}`);
  }

  // Use apiModelId for KIE.ai API call, fall back to modelId if not set
  const apiModelId = modelConfig.apiModelId || modelConfig.modelId;
  const costText = `${modelConfig.credits} credits ($${modelConfig.cost.toFixed(2)})`;
  console.log(`[KIE TTS] Using model: ${modelConfig.name} (${apiModelId}) - ${costText}`);
  console.log(`[KIE TTS] Original voiceId: ${voiceId}`);

  // KIE expects voice names (like "Rachel", "George", "Laura"), not ElevenLabs IDs
  // The voiceId is already a KIE voice name from our mapping
  const voiceForKie = voiceId;
  console.log(`[KIE TTS] Using voice for KIE: ${voiceForKie}`);

  // Prepare voice settings based on model
  const inputData: any = {
    text: text,
    voice: voiceForKie,
  };

  // Add model-specific parameters (use apiModelId for checking)
  if (apiModelId.includes('dialogue')) {
    // For dialogue models, text should be an array
    inputData.dialogue = [{ text, voice: voiceForKie }];
    delete inputData.text;
    delete inputData.voice;
  }

  if (voiceSettings && apiModelId.includes('elevenlabs')) {
    inputData.voice_settings = {
      stability: voiceSettings.stability ?? 0.5,
      similarity_boost: voiceSettings.similarityBoost ?? 0.75,
      style: voiceSettings.style ?? 0.5,
    };
  }

  try {
    // Create task via KIE unified API
    const KIE_API_URL = 'https://api.kie.ai';
    const createResponse = await fetch(`${KIE_API_URL}/api/v1/jobs/createTask`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
        'Accept': 'application/json',
      },
      body: JSON.stringify({
        model: apiModelId, // Use apiModelId for KIE.ai API call
        input: inputData,
      }),
    });

    const createData = await createResponse.json();

    if (!createResponse.ok || createData.code !== 200) {
      const errorMsg = createData.msg || createData.message || 'Failed to create KIE TTS task';
      console.error('[KIE TTS] Task creation failed:', errorMsg);
      throw new Error(`KIE AI TTS generation failed: ${errorMsg}`);
    }

    const taskId = createData.data?.taskId;
    if (!taskId) {
      throw new Error('KIE AI did not return a task ID');
    }

    console.log(`[KIE TTS] Task created: ${taskId}, polling for completion...`);

    // Poll for task completion
    const maxPolls = 30; // 1 minute max (2s intervals)
    let audioUrl: string | undefined;
    let failMessage: string | undefined;

    for (let i = 0; i < maxPolls; i++) {
      if (i > 0) {
        await new Promise(resolve => setTimeout(resolve, 2000));
      }

      const statusResponse = await fetch(
        `${KIE_API_URL}/api/v1/jobs/recordInfo?taskId=${taskId}`,
        {
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Accept': 'application/json',
          },
        }
      );

      const statusData = await statusResponse.json();

      if (!statusResponse.ok || statusData.code !== 200) {
        throw new Error(statusData.msg || statusData.message || 'Failed to check KIE task status');
      }

      const taskData = statusData.data;
      const state = taskData.state;

      console.log(`[KIE TTS] Task ${taskId} state: ${state}`);

      if (state === 'success') {
        // Extract audio URL from result
        if (taskData.resultJson) {
          try {
            const result = JSON.parse(taskData.resultJson);
            audioUrl = result.resultUrls?.[0] || result.audioUrl || result.audio_url;
            if (!audioUrl && result.audios?.length > 0) {
              audioUrl = result.audios[0];
            }
          } catch (e) {
            console.error('[KIE TTS] Failed to parse resultJson:', e);
          }
        }

        if (!audioUrl) {
          audioUrl = taskData.audioUrl || taskData.audio_url || taskData.resultUrl;
        }

        if (!audioUrl) {
          throw new Error('KIE AI completed but did not return an audio URL');
        }

        break;
      } else if (state === 'fail') {
        failMessage = taskData.failMsg || 'Audio generation failed';
        throw new Error(`KIE AI TTS generation failed: ${failMessage}`);
      }
    }

    if (!audioUrl) {
      throw new Error('KIE AI TTS generation timed out');
    }

    // Calculate costs based on character count
    const characterCount = text.length;
    const realCost = calculateVoiceCost(characterCount, 'elevenlabs'); // Use ElevenLabs pricing

    if (userId) {
      await spendCredits(
        userId,
        COSTS.VOICEOVER_LINE,
        'voiceover',
        `KIE ${modelConfig.name} TTS (${characterCount} chars)`,
        projectId,
        'kie',
        { characterCount, model: modelId, kieCredits: modelConfig.credits * Math.ceil(characterCount / 100) },
        realCost
      );
    }

    // Upload to S3 if needed
    audioUrl = await uploadMediaToS3(audioUrl, 'audio', projectId);

    return { audioUrl, cost: realCost, storage: !audioUrl.startsWith('data:') ? 's3' : 'base64' };
  } catch (error) {
    console.error('[KIE TTS] Error generating audio:', error);
    throw error;
  }
}

export async function POST(request: NextRequest) {
  // SECURITY: Rate limit generation to prevent abuse (20 requests/min)
  const rateLimitResult = await rateLimit(request, 'generation');
  if (rateLimitResult) return rateLimitResult;

  try {
    const {
      text,
      voiceId = 'pNInz6obpgDQGcFmaJgB',
      voiceName = 'Aoede',
      language = 'en',
      projectId,
      provider: requestedProvider,  // Provider from UI
      model: requestModel,  // Model from UI
      skipCreditCheck = false,      // Skip credit check when using own API key
      voiceInstructions,             // OpenAI voice instructions
      voiceStability = 0.5,          // ElevenLabs stability
      voiceSimilarityBoost = 0.75,   // ElevenLabs similarity boost
      voiceStyle = 0.5,              // ElevenLabs style
    }: TTSRequest = await request.json();

    if (!text) {
      return NextResponse.json({ error: 'Text is required' }, { status: 400 });
    }

    const authCtx = await optionalAuth();
    const sessionUserId = authCtx?.userId;
    let ttsProvider: TTSProvider = requestedProvider || 'gemini-tts';  // Use UI provider first
    let geminiApiKey = process.env.GEMINI_API_KEY;
    let elevenLabsApiKey = process.env.ELEVENLABS_API_KEY;
    let openaiApiKey = process.env.OPENAI_API_KEY;
    let kieApiKey = process.env.KIE_API_KEY;
    let kieTtsModel = requestModel || 'elevenlabs/text-to-dialogue-v3'; // Use model from request, fallback to default
    let modalTtsEndpoint: string | null = null;

    let userHasOwnApiKey = false; // Track if user has their own API key (declare outside block)

    if (sessionUserId) {
      const userApiKeys = await prisma.apiKeys.findUnique({
        where: { userId: sessionUserId },
      });

      if (userApiKeys) {
        // Only use DB provider if not specified in request
        if (!requestedProvider) {
          ttsProvider = (userApiKeys.ttsProvider as TTSProvider) || 'gemini-tts';
        }
        if (userApiKeys.geminiApiKey) {
          geminiApiKey = userApiKeys.geminiApiKey;
          userHasOwnApiKey = true;
        }
        if (userApiKeys.elevenLabsApiKey) {
          elevenLabsApiKey = userApiKeys.elevenLabsApiKey;
          userHasOwnApiKey = true;
        }
        if (userApiKeys.openaiApiKey) {
          openaiApiKey = userApiKeys.openaiApiKey;
          userHasOwnApiKey = true;
        }
        if (userApiKeys.kieApiKey) {
          kieApiKey = userApiKeys.kieApiKey;
          userHasOwnApiKey = true;
        }
        // Only use database model if not provided in request (for backward compatibility)
        if (!requestModel && userApiKeys.kieTtsModel) {
          kieTtsModel = userApiKeys.kieTtsModel;
        }
        if (userApiKeys.modalTtsEndpoint) {
          modalTtsEndpoint = userApiKeys.modalTtsEndpoint;
          userHasOwnApiKey = true;
        }
      }

      // Pre-check credit balance
      // Skip if:
      // 1. Credits were prepaid by admin for collaborator regeneration (skipCreditCheck)
      // 2. User has their own API key (they're paying the provider directly, not using platform credits)
      if (!skipCreditCheck && !userHasOwnApiKey) {
        const insufficientCredits = await requireCredits(sessionUserId, COSTS.VOICEOVER_LINE);
        if (insufficientCredits) return insufficientCredits;
      }

      // Log if user has their own API key
      if (userHasOwnApiKey) {
        console.log('[TTS] User has own API key - skipping credit check and deduction');
      }
    }

    console.log(`[TTS] Using provider: ${ttsProvider}, model: ${kieTtsModel}${skipCreditCheck ? ' (skip credit check)' : ''}`);

    // When skipCreditCheck is true OR user has own API key, pass undefined userId to prevent credit spending
    const userIdForGeneration = (skipCreditCheck || userHasOwnApiKey) ? undefined : sessionUserId;

    if (ttsProvider === 'modal') {
      if (!modalTtsEndpoint) {
        return NextResponse.json(
          { error: 'Modal TTS endpoint not configured. Please add your endpoint URL in Settings.' },
          { status: 400 }
        );
      }
      const result = await generateWithModal(text, voiceId, language, projectId, modalTtsEndpoint, userIdForGeneration);
      return NextResponse.json(result);
    }

    if (ttsProvider === 'elevenlabs') {
      if (!elevenLabsApiKey) {
        return NextResponse.json(
          { error: 'ElevenLabs API key not configured. Please add your API key in Settings.' },
          { status: 500 }
        );
      }
      const result = await generateWithElevenLabs(text, voiceId, projectId, elevenLabsApiKey, userIdForGeneration, voiceStability, voiceSimilarityBoost, voiceStyle);
      return NextResponse.json(result);
    }

    if (ttsProvider === 'openai-tts') {
      if (!openaiApiKey) {
        return NextResponse.json(
          { error: 'OpenAI API key not configured. Please add your API key in Settings.' },
          { status: 500 }
        );
      }
      const result = await generateWithOpenAI(text, voiceId, language, projectId, openaiApiKey, userIdForGeneration, voiceInstructions);
      return NextResponse.json(result);
    }

    if (ttsProvider === 'kie') {
      if (!kieApiKey) {
        return NextResponse.json(
          { error: 'KIE AI API key not configured. Please add your API key in Settings.' },
          { status: 500 }
        );
      }
      const result = await generateWithKie(
        text,
        voiceId,
        projectId,
        kieTtsModel,
        kieApiKey,
        userIdForGeneration,
        {
          stability: voiceStability,
          similarityBoost: voiceSimilarityBoost,
          style: voiceStyle,
        }
      );
      return NextResponse.json(result);
    }

    // Default to Gemini
    if (!geminiApiKey) {
      return NextResponse.json(
        { error: 'Gemini API key not configured. Please add your API key in Settings.' },
        { status: 500 }
      );
    }
    const result = await generateWithGemini(text, voiceName, language, projectId, geminiApiKey, userIdForGeneration);
    return NextResponse.json(result);

  } catch (error) {
    console.error('TTS generation error:', error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    );
  }
}
